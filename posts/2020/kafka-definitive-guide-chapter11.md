---
layout: default
title: 第11章，流式处理
---

# 第11章，流式处理
### 11.1　什么是流式处理
>先来看看什么是数据流（也被称为“事件流”或“流数据”）。首先，数据流是无边界数据集的抽象表示。无边界意味着无限和持续增长。无边界数据集之所以是无限的，是因为随着时间的推移，新的记录会不断加入进来。
知道什么是事件流以后，是时候了解“流式处理”的真正含义了。流式处理是指实时地处理一个或多个事件流。流式处理是一种编程范式，就像请求与响应范式和批处理范式那样。

~Java8实战这本书中也有类似的定义，放在这里当做加深记忆。



>流式处理，这种范式介于上述两者之间（请求与响应范式和批处理范式）。大部分的业务不要求亚毫秒级的响应，不过也接受不了要等到第二天才知道结果。大部分业务流程都是持续进行的，只要业务报告保持更新，业务产品线能够持续响应，那么业务流程就可以进行下去，而无需等待特定的响应，也不要求在几毫秒内得到响应。一些业务流程具有持续性和非阻塞的特点，比如针对可疑信用卡交易的警告、网络警告、根据供应关系实时调整价格、跟踪包裹。  
流的定义不依赖任何一个特定的框架、API或特性。只要持续地从一个无边界的数据集读取数据，然后对它们进行处理并生成结果，那就是在进行流式处理。重点是，整个处理过程必须是持续的。一个在每天凌晨两点启动的流程，从流里读取500条记录，生成结果，然后结束，这样的流程不是流式处理。  

~什么是流式处理，什么不是？这里提供很好的答案。


#### 11.2.3　流和表的二元性
>在将表与流进行对比时，可以这么想：流包含了变更——流是一系列事件，每个事件就是一个变更。表包含了当前的状态，是多个变更所产生的结果。所以说，表和流是同一个硬币的两面——世界总是在发生变化，用户有时候关注变更事件，有时候则关注世界的当前状态。如果一个系统允许使用这两种方式来查看数据，那么它就比只支持一种方式的系统强大。

~需要理解。



### 11.4　Streams示例
>Kafka有两个基于流的API，一个是底层的Processor API，一个是高级的Streams DSL。  
在使用DSL  API时，一般会先用StreamBuilder创建一个拓扑（topology）。拓扑是一个有向图（DAG），包含了各个转换过程，将会被应用在流的事件上。在创建好拓扑后，使用拓扑创建一个KafkaStreams执行对象。多个线程会随着KafkaStreams对象启动，将拓扑应用到流的事件上。在关闭KafkaStreams对象时，处理也随之结束。

~知道上面的内容，就能够更好地理解流处理相关的代码。



### 11.6　流式处理使用场景
>每一种场景都有自己的特点，不过目标是一样的——处理大量来自设备的事件，并识别出一些模式，这些模式预示着某些设备需要进行维护，比如交换机数据包的下降、生产过程中需要更大的力气来拧紧螺丝，或者用户频繁重启有线电视的机顶盒。

~我想很多场景都是如此：处理大量的事件，并从中识别出一些模式，这些模式能够预测一些异常事件的发生，比如信用卡欺诈、股票交易欺诈、视频游戏作弊或者网络安全风险，还有上面所说的物联网中检测设备的异常。另外还可以根据这些模型得知哪些事物还需要改善。
